{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample From Mesh Files & Load Proteins\n",
    "\n",
    "In this notebook, point clouds are created from mesh files using poisson disk sampling."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T13:41:41.147036Z",
     "start_time": "2025-01-04T13:41:39.240287Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_mesh_and_sample_points(file_name, num_points=5000):\n",
    "    # Default number of points as indicated in the thesis\n",
    "    mesh = o3d.io.read_triangle_mesh(file_name)\n",
    "    pc = mesh.sample_points_poisson_disk(num_points)\n",
    "    return np.asarray(pc.points)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data and convert to point clouds\n",
    "path = 'mesh_files_new'\n",
    "count = 0\n",
    "for idx, file in tqdm(enumerate(os.listdir(path))):\n",
    "    file_path = os.path.join(path, file)\n",
    "    if os.path.isfile(file_path):\n",
    "        label = \"\"\n",
    "        for s in file[:-3]:\n",
    "            if s.isalpha():\n",
    "                label += s\n",
    "        point_cloud = load_mesh_and_sample_points(file_path)\n",
    "        np.savez('point_clouds/' + label + str(count) + '.npz', objects=point_cloud, classes=label)\n",
    "        count += 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This step was only needed once\n",
    "# Can be ignored\n",
    "path = 'point_clouds'\n",
    "objects = []\n",
    "labels = []\n",
    "for idx, file in tqdm(enumerate(os.listdir(path))):\n",
    "    file_path = os.path.join(path, file)\n",
    "    if os.path.isfile(file_path):\n",
    "        load_table = np.load(file_path, allow_pickle=True)\n",
    "        if len(load_table['objects'].shape) > 2:\n",
    "            for i in range(load_table['objects'].shape[0]):\n",
    "                objects.append(load_table['objects'][i])\n",
    "                labels.append(load_table['classes'][i])\n",
    "        else:\n",
    "            objects.append(load_table['objects'])\n",
    "            labels.append(load_table['classes'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.savez('point_clouds/all_point_clouds', objects=objects, labels=labels)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "load_clouds = np.load('point_clouds/mc_gill_whole.npz', allow_pickle=True)\n",
    "point_cloud_data = [load_clouds['objects'], load_clouds['labels']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_scatterplot_3d(data, descriptor):\n",
    "    figure = plt.figure(figsize=(5, 5))\n",
    "    ax = figure.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Map classes to colors\n",
    "    unique_classes = data['class'].unique()\n",
    "    colors = plt.cm.tab10(range(len(unique_classes)))\n",
    "    class_color_map = dict(zip(unique_classes, colors))\n",
    "\n",
    "    # Plot points by class\n",
    "    for class_label in unique_classes:\n",
    "        class_data = data[data['class'] == class_label]\n",
    "        ax.scatter(\n",
    "            class_data['evrap_x'], class_data['evrap_y'], class_data['evrap_z'],\n",
    "            color=class_color_map[class_label], label=class_label, s=50\n",
    "        )\n",
    "\n",
    "    ax.legend()\n",
    "    ax.view_init(80, 10)\n",
    "    ax.set_title(descriptor)\n",
    "\n",
    "\n",
    "def create_scatterplot_2d(data, descriptor):\n",
    "    figure = plt.figure(figsize=(5, 5))\n",
    "    ax = figure.add_subplot(111)\n",
    "\n",
    "    # Map classes to colors\n",
    "    unique_classes = data['class'].unique()\n",
    "    colors = plt.cm.tab10(range(len(unique_classes)))\n",
    "    class_color_map = dict(zip(unique_classes, colors))\n",
    "\n",
    "    # Plot points by class\n",
    "    for class_label in unique_classes:\n",
    "        class_data = data[data['class'] == class_label]\n",
    "        ax.scatter(\n",
    "            class_data['samp_x'], class_data['samp_y'],\n",
    "            color=class_color_map[class_label], label=class_label, s=50\n",
    "        )\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title(descriptor)\n",
    "\n",
    "\n",
    "def create_scatterplot_1d(data, descriptor):\n",
    "    figure = plt.figure(figsize=(5, 5))\n",
    "    ax = figure.add_subplot(111)\n",
    "\n",
    "    # Map classes to colors\n",
    "    unique_classes = data['class'].unique()\n",
    "    colors = plt.cm.tab10(range(len(unique_classes)))\n",
    "    class_color_map = dict(zip(unique_classes, colors))\n",
    "\n",
    "    # Plot points by class\n",
    "    for class_label in unique_classes:\n",
    "        class_data = data[data['class'] == class_label]\n",
    "        x = np.arange(len(class_data[descriptor]))\n",
    "        ax.scatter(\n",
    "            x, class_data[descriptor], color=class_color_map[class_label], label=class_label,\n",
    "        )\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title(descriptor)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Runtime Overview\n",
    "\n",
    "The descriptors used have the following complexities. \n",
    "\n",
    "- EVARP: $O(nm)$\n",
    "- SAMP: $O(nm)$\n",
    "- SCOMP: $O(n \\cdot (m$ log $m)$\n",
    "- SIRM: $O(nm)$\n",
    "- Shell Model: $O(nm)$\n",
    "- Sector Model: $O(nm)$\n",
    "- Combined Model: $O(n(m + m))$\n",
    "- FPFH: $O(nmk)$\n",
    "\n",
    "Notation:\n",
    "- n: Number of point clouds\n",
    "- m: Number of points per point cloud\n",
    "- k: A hyperparameter of FPFH (relatively small), similar to k in k-NN"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare Proteins"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T13:48:18.288307Z",
     "start_time": "2025-01-04T13:48:18.270041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from Bio.PDB import *    "
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T13:48:18.610917Z",
     "start_time": "2025-01-04T13:48:18.592234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# https://search.rcsb.org/index.html#building-search-request\n",
    "# https://search.rcsb.org/index.html#search-example-4\n",
    "# https://www.rcsb.org/docs/search-and-browse/advanced-search/structure-similarity-search\n",
    "def fetch_cluster_ids(entry_id):\n",
    "    url = 'https://search.rcsb.org/rcsbsearch/v2/query'\n",
    "\n",
    "    query_dict = {\n",
    "        \"query\": {\n",
    "            \"type\": \"terminal\",\n",
    "            \"service\": \"structure\",          # structural similarity is what we want\n",
    "            \"parameters\": {\n",
    "                \"value\": {\n",
    "                    \"entry_id\": entry_id,\n",
    "                    \"assembly_id\": \"1\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"return_type\": \"entry\",\n",
    "        \"request_options\": {\n",
    "            \"paginate\": {\n",
    "                \"start\": 0,\n",
    "                \"rows\": 100\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    query_response = requests.post(url, json=query_dict)\n",
    "    results = query_response.json()\n",
    "        \n",
    "    candidate_cluster_ids = []\n",
    "    for entry in results['result_set']:\n",
    "        entry_id = entry['identifier']\n",
    "        score = entry['score']\n",
    "        \n",
    "        # this value is arbitrary for now\n",
    "        if score > 0.2:\n",
    "            candidate_cluster_ids.append(entry_id)\n",
    "    \n",
    "    return candidate_cluster_ids"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Problem: RCSB only has information about whether a protein is in its native confirmation in some cases, therefore we can not guarantee to build clusters of similar items. AlphaFold DB on the other hand has no tool to query similar proteins.\n",
    "\n",
    "Generally, what do we want to cluster? Just get proteins in similar structure from the database, since they commonly also have similar functions? This creates a high bias, but is probably the only way.\n",
    "\n",
    "Next: How similar should proteins be based on their similarity score?\n",
    "\n",
    "Protein suggestions:\n",
    "\n",
    "- 1A4U - Hemoglobin, a protein responsible for oxygen transport in the blood.\n",
    "- 1GZX - Lysozyme, an enzyme that breaks down bacterial cell walls.\n",
    "- 1UBQ - Ubiquitin, a small regulatory protein involved in protein degradation.\n",
    "- 3MHT - DNA polymerase I, an enzyme that synthesizes DNA molecules.\n",
    "- 4HHB - Myoglobin, a protein that stores oxygen in muscle tissue.\n",
    "- 6VXX - SARS-CoV-2 spike glycoprotein, involved in viral entry into host cells.\n",
    "- 2RH1 - Beta-2 adrenergic receptor, a G-protein coupled receptor (GPCR).\n",
    "- 5XTL - Insulin receptor, important for glucose metabolism regulation.\n",
    "- 3KZ8 - Cytochrome c oxidase, involved in the electron transport chain.\n",
    "- 2C9T - Glutamate receptor, a ligand-gated ion channel in the nervous system.\n",
    "\n",
    "- Note 4.01.2025: 1GZX deleted, since it has too many overlaps with myoglobin."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T13:48:28.761222Z",
     "start_time": "2025-01-04T13:48:20.974230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "identifiers = [\"1A4U\", \"1UBQ\", \"3MHT\", \"4HHB\", \"6VXX\", \"2RH1\", \"5XTL\", \"3KZ8\", \"2C9T\"]\n",
    "\n",
    "candidate_clusters = []\n",
    "for protein_id in tqdm(identifiers):\n",
    "    candidate_ids = fetch_cluster_ids(protein_id)\n",
    "    candidate_clusters.append(candidate_ids)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:07<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T13:48:28.791520Z",
     "start_time": "2025-01-04T13:48:28.772734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = {\n",
    "    'id': [],\n",
    "    'label': []\n",
    "}\n",
    "identifier = 0\n",
    "for cluster in candidate_clusters:\n",
    "    print(len(cluster))\n",
    "    for protein_id in cluster:\n",
    "        labels['id'].append(protein_id)\n",
    "        labels['label'].append(identifier)\n",
    "    identifier += 1"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "44\n",
      "27\n",
      "100\n",
      "43\n",
      "19\n",
      "67\n",
      "23\n",
      "1\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T13:42:01.272544Z",
     "start_time": "2025-01-04T13:42:01.249886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels_df = pd.DataFrame(labels)\n",
    "labels_df.to_csv('point_clouds/proteins/labels.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def download_protein_by_id(entry_id):\n",
    "    url = f\"https://files.rcsb.org/download/{entry_id}.cif\"\n",
    "    protein_path = f'point_clouds/proteins/cif/{entry_id}.cif'\n",
    "\n",
    "    if not os.path.isfile(protein_path):\n",
    "        query_response = requests.get(url)\n",
    "        if query_response.status_code == 200:\n",
    "            with open(path, \"wb\") as f:\n",
    "                f.write(query_response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for cluster in tqdm(candidate_clusters):\n",
    "    for protein_id in cluster:\n",
    "        download_protein_by_id(protein_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T13:52:00.218556Z",
     "start_time": "2025-01-04T13:48:50.646503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parser = MMCIFParser()\n",
    "\n",
    "point_clouds_data = []\n",
    "labels = []\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")       # there are a lot of structural mistakes in PDB\n",
    "for cluster in tqdm(candidate_clusters):\n",
    "    for protein_id in cluster:\n",
    "        structure = parser.get_structure(\"PHA-L\", f\"point_clouds/proteins/cif/{protein_id}.cif\")\n",
    "        coordinates = []\n",
    "        for model in structure:\n",
    "            for chain in model:\n",
    "                for residue in chain:\n",
    "                    for atom in residue:\n",
    "                        # Get the atomic coordinates (x, y, z)\n",
    "                        coord = atom.coord\n",
    "                        coordinates.append(coord)\n",
    "        if len(labels_df.loc[labels_df['id'] == protein_id, 'label']) > 1:\n",
    "            continue\n",
    "        point_clouds_data.append(np.array(coordinates))\n",
    "        label = labels_df.loc[labels_df['id'] == protein_id, 'label'].iloc[0]\n",
    "        labels.append(label)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:09<00:00, 21.06s/it]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T13:54:05.598329Z",
     "start_time": "2025-01-04T13:54:05.573687Z"
    }
   },
   "cell_type": "code",
   "source": "len(labels)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T13:52:00.245573Z",
     "start_time": "2025-01-04T13:52:00.229292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "def save_proteins(point_clouds, clusters):\n",
    "    pc_dict = {\n",
    "        'objects': point_clouds,\n",
    "        'labels': clusters\n",
    "    }\n",
    "    with open('point_clouds/proteins.pkl', 'wb') as f:\n",
    "        pickle.dump(pc_dict, f)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T13:52:00.324612Z",
     "start_time": "2025-01-04T13:52:00.284375Z"
    }
   },
   "cell_type": "code",
   "source": "save_proteins(point_clouds_data, labels)",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
